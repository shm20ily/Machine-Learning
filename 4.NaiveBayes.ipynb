{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5586f00",
   "metadata": {},
   "source": [
    "## 简介\n",
    "- 朴素贝叶斯法是基于贝叶斯定理和特征条件独立假设的分类方法。对于给定训练数据集，首先基于特征条件独立性假设学习输入和输出的联合概率分布；然后基于此模型，对给定的输入新实例x，利用贝叶斯定理求出最大的后验概率输出y。\n",
    "- 朴素贝叶斯不会直接学习输入和输出的联合概率分布，而是通过学习类的先验概率和类条件概率来完成。\n",
    "\n",
    "- 朴素贝叶斯法包括朴素贝叶斯法的学习与分类、朴素贝叶斯法的参数估计算法。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cccd7e",
   "metadata": {},
   "source": [
    "## 1、全概率公式与贝叶斯定理\n",
    "- 概率：事件X发生的可能性就被称为X发生的概率，用~P(X)来表示\n",
    "- 先验概率：通过经验来判断事件发生的概率，或当这个概率分布在进行现场试验或者抽样前就已确定\n",
    "- 后验概率：在已知结果的前提下，推测其造成的原因的概率\n",
    "- 条件概率：当事件Y已经发生的时候，事件X发生的可能性，称为在Y条件下X发生的条件概率，用~P(X|Y)表示\n",
    "\n",
    "> 先验概率分布：\n",
    "> $P(Y=c_{k})，k=1，2，...，k$ \n",
    "> 条件概率分布：\n",
    "> $P(X=x|Y=c_{k})=P(X^{1}=x^{1},...,X^{n}=x^{n}|Y=c_{k}),k=1,2,...,k$\n",
    "- 全概率公式：\n",
    "P(X) =P(Y1) x P(X | Y1) x P(Y2) x P(X | Y2) x...x P(Yn) x P(X | Yn)\n",
    "- 贝叶斯定理：\n",
    " $p(Y=c_{k}|X=x)=\\frac{P(X=x|Y=c_{k})P(Y=c_{k})}{\\sum_{k}^{}P(X=x|Y=c_{k})P(Y=c_{k})}$\n",
    " \n",
    " **区分**：\n",
    " ![在这里插入图片描述](https://img-blog.csdnimg.cn/485e8289f15a45beaf0a56f33ba695da.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05addc1",
   "metadata": {},
   "source": [
    "## 2、朴素贝叶斯理论\n",
    "- 朴素贝叶斯法通过训练数据集学习联合概率分布P（X，Y），也就是说，通过学习类先验概率分布和类条件概率分布来实现。\n",
    "- 朴素贝叶斯法对条件概率分布作了**条件独立性**的假设。其名字来源于贝叶斯定理和一个朴素的假设：所有特征的条件都相互独立于其他给定的响应变量，即特征的条件独立性假设。\n",
    "\n",
    "\n",
    "> 条件独立性假设：\n",
    "> $P(X=x|Y=c_{k})=\\prod_{j=1}^{n}P(X^{(j)}=x^{(j)}|Y=c_{k})$\n",
    "\n",
    "- 朴素贝叶斯法实际上学习到生成数据的机制，所以属于生成型。条件独立假设等于说明用于分类的特征在类确定的条件下都是条件独立的，该假设使得朴素贝叶斯的学习成为可能。\n",
    "- 虽然这一假设使得朴素贝叶斯法变得简单，但难免也会牺牲一定的分类准确率。\n",
    "\n",
    "- **朴素贝叶斯法分类时，对给定的输入x，通过学习到的模型计算后验概率分布$P(Y=c_{k}|X=x)$，将后验概率最大的类作为x的类输出。**\n",
    "\n",
    "\n",
    "\n",
    "> 朴素贝叶斯分类器：\n",
    "> $y=f(x)=argmax\\frac{P(Y=c_{k})\\prod_{j}^{}P(X^{(j)}=x^{(j)}|Y=c_{k})}{\\sum_{k}^{}P(Y=c_{k})\\prod_{j}^{}P(X^{(j)}=x^{(j)}|Y=c_{k})}$\n",
    "> 分母对所有$c_{k}$都相同：\n",
    "> $y=arg maxP(Y=c_{k})\\prod_{j}^{}P(X^{j}=x^{j}|Y=c_{k})$\n",
    "\n",
    "- 求X用全概率公式，求Y用贝叶斯定理\n",
    "![在这里插入图片描述](https://img-blog.csdnimg.cn/65546d1d040c4c34b8d60419fac96087.png#pic_center)\n",
    "\n",
    "\n",
    "- **朴素贝叶斯的基本方法**：在统计数据的基础上，依据条件概率公式，计算当前特征的样本属于某个分类的概率，选最大的概率分类\n",
    "\n",
    "- 该模型被称之为朴素是因为它假设对响应变量来说所有的特征都条件独立，但该假设不等同于所有的特征相互独立。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a911bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==[-0.8, -1]预测结果==\n",
      "[1]\n",
      "==[3,2]预测结果==\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    "Y = np.array([1, 1, 1, 2, 2, 2])\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf = GaussianNB()\n",
    "\n",
    "# 拟合数据\n",
    "clf.fit(X, Y)\n",
    "print(\"==[-0.8, -1]预测结果==\")\n",
    "print(clf.predict([[-0.8, -1]]))\n",
    "print(\"==[3,2]预测结果==\")\n",
    "print(clf.predict([[3, 2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33886ba",
   "metadata": {},
   "source": [
    "## 3、贝叶斯决策理论方法\n",
    "- 在分类问题中，我们会将未知标签的数据集特征与我们已知标签的特征进行比较。朴素贝叶斯，就是这样一种比较的方法。\n",
    "\n",
    "**基本思想**：\n",
    "- **1**、已知类条件概率密度参数表达式和先验概率\n",
    "- **2**、利用贝叶斯公式转换成后验概率\n",
    "- **3**、根据后验概率大小进行决策分类\n",
    "\n",
    "## 4、朴素贝叶斯分类器实战 \n",
    "- 朴素⻉叶斯分类最适合的场景就是文本分类、情感分析和垃圾邮件识别。其中情感分析和垃圾 邮件识别都是通过⽂本来进⾏判断。\n",
    "- 从这⾥你能看出来，这三个场景本质上都是文本分类，这 也是朴素⻉叶斯最擅⻓的地⽅。所以朴素⻉叶斯也常⽤于⾃然语⾔处理 NLP 的⼯具。\n",
    "\n",
    "- sklearn 机器学习包 sklearn 的全称叫 Scikit-learn，它给我们提供了 3 个朴素⻉叶斯分类算法，分别是⾼斯朴 素⻉叶斯（GaussianNB）、多项式朴素⻉叶斯（MultinomialNB）和伯努利朴素⻉叶斯 （BernoulliNB），它们的区别在于特征向量x的分布情况。\n",
    "\n",
    "根据算法的特征类型将其分成两类。\n",
    "- 连续：这意味着最终的标签为实值（可以存在小数）\n",
    "- 离散：这以为着最终的结果为分类的类别值（只能为整数）\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6d5602",
   "metadata": {},
   "source": [
    "## 5、贝叶斯分类算法\n",
    " \n",
    "- 贝叶斯分类算法是基于贝叶斯定理和特征条件独立假设的分类方法。\n",
    "\n",
    "这三种算法适合应⽤在不同的场景下，我们应该根据特征变量的不同选择不同的算法：\n",
    "##### 高斯朴素贝叶斯\n",
    " -  高斯朴素贝叶斯（连续）：特征变量是连续变量，符合高斯分布\n",
    " \t- 比如说⼈的身高，物体的长度。 \n",
    " ![在这里插入图片描述](https://img-blog.csdnimg.cn/c6b4dc1632e44341ad3c807776f55710.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f5dbda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Purple']\n"
     ]
    }
   ],
   "source": [
    "#导入相应的包\n",
    "import numpy as np\n",
    "#导入高斯模型\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#样本X包含三个特征，分别是Red的百分比，Green的百分比，Blue的百分比\n",
    "#每个特征的值都是（0,1）之间的小数\n",
    "\n",
    "#首先我们创建一个训练集\n",
    "X = np.array([[0.5, 0, 0.5], [1, 1, 0], [0, 0, 0]])\n",
    "#给定我们训练集的分类标签\n",
    "y = np.array(['Purple', 'Yellow', 'Black'])\n",
    "\n",
    "#运用高斯模型去训练数据\n",
    "clf = GaussianNB()\n",
    "#训练数据集\n",
    "clf.fit(X, y)\n",
    "\n",
    "#下面我们运用我们的模型进行测试\n",
    "#比如我们试一下，red 0.5，green 0.5，blue 0.5\n",
    "print(clf.predict([[0.5, 0.5, 0.5]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9137de10",
   "metadata": {},
   "source": [
    "##### 多项式朴素贝叶斯\n",
    " - 多项式朴素贝叶斯（离散）：特征变量是离散变量，符合多项分布，当特征都是分类型特征时，可使用多项式模型。多项分布描述了在样本标签中的概率分布。\n",
    " - 可用它来计算特征中分类的出现频率。特别的是，当特征只有两种的时候，将会使用多项式模型中的伯努利模型。\n",
    " \t- 在文档分类中特征变量体现在 ⼀个单词出现的次数\n",
    " \t- 或者是单词的 TF-IDF 值等。\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52244de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Apple']\n"
     ]
    }
   ],
   "source": [
    "#导入相关的包\n",
    "import numpy as np\n",
    "#导入多项式模型\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#我们使用文章最开始的水果的数据集作为示例\n",
    "#水果数据集的样本X具有三个特征[Size, Weight, Color]\n",
    "#每个特征共有三种分类\n",
    "#由于python不能直接识别文字\n",
    "#所以将这个三个特征的不同分类重新编码如下\n",
    "# Size: 0 = Small, 1 = Moderate, 2 = Large\n",
    "# Weight: 0 = Light, 1 = Moderate, 2 = Heavy\n",
    "# Color: 0 = Red, 1 = Blue, 2 = Brown\n",
    "\n",
    "#用编码好的数据创建训练集\n",
    "X = np.array([[1, 1, 0], [0, 0, 1], [2, 2, 2]])\n",
    "#给训练集的数据创建标签\n",
    "y = np.array(['Apple', 'Blueberry', 'Coconut'])\n",
    "\n",
    "#运用多项式模型训练数据\n",
    "clf = MultinomialNB()\n",
    "#训练水果数据集\n",
    "clf.fit(X, y)\n",
    "\n",
    "#预测数据集\n",
    "#比如我们试一下 size = 1，weight = 2，color = 0\n",
    "print(clf.predict([[1, 2, 0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a243f2",
   "metadata": {},
   "source": [
    "##### 伯努利朴素贝叶斯\n",
    " -  伯努利朴素贝叶斯（离散）：特征变量是布尔变量，符合 0/1 分布，通常来说就是二分类标签。上文中提到，当特征只有两种的时候，我们可以使用伯努利模型。\n",
    " - 与多项式模型不同，在这里只计算一个特征是否发生。\n",
    " \t- 比如，本页面是否存在【多项式】这三个字，答案只有两种，存在or不存在。\n",
    " \t- 伯努利模型的条件概率计算方法与多项式模型一致。 在文档分类中特征是单词是否出现。\n",
    " ![在这里插入图片描述](https://img-blog.csdnimg.cn/144e825627904773ac92c95780ae5922.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81208bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Duck']\n"
     ]
    }
   ],
   "source": [
    "#导入包\n",
    "import numpy as np\n",
    "#导入伯努利模型\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "#数据集X的特征有三个，分别是\n",
    "# Walks like a duck\n",
    "# Talks like a duck\n",
    "# Is small]\n",
    "#这三个特征分别有两种分布，是or否\n",
    "# Walks like a duck: 0 = False, 1 = True\n",
    "# Talks like a duck: 0 = False, 1 = True\n",
    "# Is small: 0 = False, 1 = True\n",
    "\n",
    "#创建训练集\n",
    "X = np.array([[1, 1, 0], [0, 0, 1], [1, 0, 0]])\n",
    "#给训练集创建标签\n",
    "#是鸭子or不是鸭子\n",
    "y = np.array(['Duck', 'Not a Duck', 'Not a Duck'])\n",
    "\n",
    "#使用伯努利模型训练数据\n",
    "clf = BernoulliNB()\n",
    "#训练数据集\n",
    "clf.fit(X, y)\n",
    "\n",
    "#预测数据集\n",
    "#比如我们试一下 三个特征都为true的时候，到底是不是鸭子\n",
    "print( clf.predict([[1, 1, 1]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
